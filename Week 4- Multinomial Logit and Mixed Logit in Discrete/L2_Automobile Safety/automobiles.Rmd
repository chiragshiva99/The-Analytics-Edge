---
title: "Analytics on car safety feature data"
author: "Stefano Galelli"
date: "Term 5, 2022"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: yes
    toc_depth: 2
    number_sections: yes
---


# Automobile  safety data

First we load the data and investigate the different attributes and characteristics.

```{r, results='hide'}
rm(list=ls())
safety <- read.csv("safetydata.csv")
str(safety)
#View(safety)
```

We have 9500 observations on 112 variables. There are a total of 500 customers and each of them performs 19 choice tasks.

* `Case`: Customer number (1 to 500).
* `No`: Observation number (1 to 9500).
* `Task`: Task number for a customer (1 to 19).

Each customer makes a choice among four packages in each choice task (stated preference data sheet). For example customer 1 in the first choice task opted for `Ch2`.

<img src=Autochoices.png width="500px">

## Car attributes

The variables related to the attributes of the cars are the following (the number beside them are between 1 to 4 and relates to the choice among 1 to 4 that attribute is a part):

* `CC` - Cruise control - 3 levels
* `GN` - Go notifier - 2 levels
* `NS` - Navigation system -    5 levels
* `BU` - Backup aids - 6 levels
* `FA` - Front park assist - 2 levels
* `LD` - Lane departure - 3 levels
* `BZ` - Blind zone alert - 3 levels
* `FC` - Front collision warning - 2 levels
* `FP` - Front collision protection - 4 levels
* `RP` - Rear collision protection - 4 levels
* `PP` - Parallel park aids - 3 levels
* `KA` - Knee air bags - 2 levels
* `SC` - Side air bags - 4 levels
* `TS` - Emergency notification - 3 levels
* `NV` - Night vision system - 3 levels
* `MA` - Driver assisted adjustment - 4 levels
* `LB` - Low speed breaking assist - 4 levels
* `AF` - Adaptive Front lighting - 3 levels
* `HU` - Head up display - 2 levels
* `Price` - Price - 11 levels (300, 1000, 1500, 2000, 2500, 3000, 4000, 5000, 7500, 10000, 12000)

## Demographic information

The variables starting from `segment` until `income` provide demographic information.

* `segment` = segment of car population that individual belongs to
* `year` = year
* `miles` = mileage
* `night` = % of time customer drives at night
* `gender` = gender (Female or Male)
* `age` = age bracket
* `educ` = Education level (college (4 years), Grade School, High School, Postgrad, college(1-3 yrs), vocational school)
* `region` = resident of region (MW, NE, SE, SW, W)
* `Urb` = resident of  Rural, Suburban, Urban
* `income` = income

## The choice variables

* `Ch1` = 1 if package 1 is chosen, 0 otherwise
* `Ch2` = 1 if package 2 is chosen, 0 otherwise
* `Ch3` = 1 if package 3 is chosen, 0 otherwise
* `Ch4` = 1 if package 4 is chosen, 0 otherwise
* `Choice` = Ch1 or Ch2 or Ch3 or Ch4 (depending on which option is chosen)

```{r}
table(safety$Choice)
safety$Choice <- as.numeric(sub("Ch","",safety$Choice))
table(safety$Choice)
```

```{r}
which(colnames(safety)=="CC1") #checking column names
which(colnames(safety)=="Price4")
```

* Columns 4 to 83 of the safety data frame contains the attribute levels for each of the 4 alternatives (choices) indexed by 1,2,3 and 4 respectively.  
* Note the zero level in all cases indicate that the attribute is not available.
* The fourth choice is the NONE option meaning none of the attributes are available for the option.
* In general higher levels for attributes correspond to more technically advanced features. We can capture the variables either directly or by adding dummy variables that take a value of 1 or 0 depending on the level.  


# Multinomial logit model

## Proper formatting of the data

`dfidx`: This command does the following for our current execution (see R code below): 

  * reads a subset of the dataframe where we use the first 12 choice tasks for each customer in our training set (12 out of 19),  
  * indicates that the` shape` of the dataframe is `wide` (where each row is an observation),  
  * indicates that the variable indicating the choice made is defined by `Choice`,  
  * indicates that the separator of the variable name and the alternative name is *blank* indicated by "" (this helps to guess the variables and the alternative name),  
  * indicates that the attributes are in columns 4 to 83 by the parameter specification `varying =c(4:83)` (helps indicate the variable indices that are alternative specific),  
  * indicates that `idx` identifies the indices in the data set,
  * Specifies the index for alternatives with the parameter `idnames`. Notice that we indicate the first one as `NA` which means it relates to the indices given in `idx` and additionally  
   the second one `alt` specifies the four alternatives.  

This creates a dataframe of the long format to which we can use the `mlogit` package.

`dfidx` *is an alternative to the command `mlogit.data`. Unfortunately in this example `mlogit.data` does not seem to work properly.*

```{r results='hide'}
library(mlogit)
# library(dfidx)
# View(safety)
S <- dfidx(subset(safety, Task<=12), shape="wide", choice="Choice", varying =c(4:83), sep="", idx = list(c("No", "Case")), idnames = c(NA, "alt")) #Task <= 12 for training and Task >12 for testing
```

```{r results='hide'}
head(S)
#str(S)
```

## Fitting a Multinomial logit (MNL) model

```{r}
M <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data=S)
summary(M) #using model
```

We compute and observe the following:

* Log-likelihood at optimality is $LL(\hat{\beta}) = -7567.9$
* AIC $= -2LL(\hat{\beta})+ 2(parameters) = 15175.8$  
* Likelihood Ratio (McFadden Index) = $\rho = 1-\frac{LL(\hat{\beta})}{LL(0)} = 1 - \frac{-7567.8}{6000 \log 1/4} = 1-\frac{-7567.9}{-8317.76} = 0.09$.
* Results indicate that `CC` (cruise control), `KA` (knee air bags), `TS` (emerging notification), `MA` (driver adjusted assessment), `Price` are very significant at 0.001 level. As should be expected, `Price` has a negative coefficient.
* `LD` (lane departure) and `SC` (side air bags) are significant at 0.01 level.
* The non-price coefficients have positive signs indicating that these are valued (higher levels of safety features). 

## Willingness to Pay

* The ratio of $\beta_j$ coefficients can be used to estimate the willingness to pay for a particular attribute. 

* Suppose $\beta_1$ is the coefficient for attribute 1 and $\beta_2$ is the coefficient of attribute 2 (Price). Note that $\beta_2$ will be typically negative since more the price, lesser the utility. Say $\beta_1$ is positive.

 $$U= \beta_1 x_1 + \beta_2 x_2 + \ldots$$

* Assume unit change (increase) in attribute 1.

$$U  = \beta_1(x_1 +1) + \beta_2 (x_2 + \Delta)+ \ldots$$

* Then $\Delta= \frac{-\beta_1}{\beta_2}$. Hence $\Delta$ is the willingness to pay for unit increase in attribute.

```{r}
wtp<- as.numeric(-M$coefficients["CC"]/M$coefficients["Price"])
wtp
```

* For example, the willingness to pay for cruise control  is given by:  

$$WTP = \frac{0.1085}{0.2036} = 0.5330.$$

-------


# Predictions

First we check the prediction accuracy in our training model based on the maximum predicted choice probability:

```{r}
ActualChoice <- subset(safety, Task<=12)[,"Choice"] #checking actual choices vs predicted choices
P <- predict(M, newdata=S) #compare the choices #P[12:] vs ActualChoice[12]
PredictedChoice <- apply(P,1,which.max)
```

`ActualChoice` keeps track of actual observed choices. `P` predicts the choice probability for the given dataset. The `apply` function applies to the matrix `P`, across rows (indexed by 1), the function of `which.max` (identifies index that is maximum).

```{r}
Tabtrain=table(PredictedChoice, ActualChoice)
Tabtrain

CorPredTrain<-sum(diag(Tabtrain))/sum(Tabtrain)
CorPredTrain
```

* Prediction accuracy on the training set = $\frac{616+647+629+700}{6000} = 0.432.$

Assuming a complete random choice for predicting the choice would result in a prediction accuracy of 0.25.

```{r}
Test <-dfidx(subset(safety, Task>12), shape="wide", choice="Choice", varying =c(4:83), sep="",idx = list(c("No", "Case")), idnames = c(NA, "alt"))

TestPredict <- predict(M, newdata=Test)
ActualChoice <- subset(safety, Task>12)[,"Choice"]

PredictedChoice <- apply(TestPredict, 1, which.max)
Tabtest=table(PredictedChoice, ActualChoice)

Tabtrain
Tabtest

CorPredTest<-sum(diag(Tabtest))/sum(Tabtest)
CorPredTest
```

* Prediction accuracy on the test set = $\frac{376+435+356+517}{3500} = 0.481.$  


# Building more sophisticated models

Now we build a mixed logit model below where parameters follow a normal distribution.

```{r results='hide'}
M1 <- mlogit(Choice~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1, data=S, rpar=c(CC='n', GN='n', NS='n', BU='n',FA='n',LD='n',BZ='n',FC='n',FP='n',RP='n',PP='n',KA='n',SC='n',TS='n',NV='n',MA='n',LB='n',AF='n',HU='n',Price='n'), panel = TRUE, print.level=TRUE)
```

This fits a mixed logit model where the coefficients are treated as random variables. This is captured with `rpar` (random parameters) argument where `'n'` indicates it is modeled as a normal random variable, panel data captures the fact that we have multiple observations per individual.

```{r}
summary(M1)
```

For each random coefficient we estimate a mean value and a standard deviation.

## Comparison with MNL

```{r}
#M$logLik
Mloglik <- round(as.numeric(M$logLik),digits=2)
AICM <- -2*Mloglik + 2*20

M1loglik <- round(as.numeric(M1$logLik),digits=2)
AICM1 <- -2*M1loglik +2*40

Mloglik
AICM

M1loglik
AICM1
```

Hence we obtain  

  * log-likelihood for MNL = -7567.93.   
  * log-likelihood for Mixed logit model = -6531.3.  
  
Moreover,  

  * AIC for MNL = 15175.86.
  * AIC for Mixed logit model = 13142.6.  

Hence log-likelihood for the Mixed logit model is higher than than of the MNL model; moreover, the AIC for Mixed logit model is lower than that of the MNL model. Therefore from this perspective the Mixed logit model is preferred.

## Predictions

### Comparison on training data

```{r}
P1 <- predict(M1, newdata=S)
PredictedChoice1 <- apply(P1, 1, which.max)
ActualChoice <- subset(safety, Task<=12)[,"Choice"]

Tabtrainmixed <- table(PredictedChoice1, ActualChoice)
CorPredTrmix <- sum(diag(Tabtrainmixed))/sum(Tabtrainmixed)

Tabtrain
CorPredTrain

Tabtrainmixed
CorPredTrmix
```

* Prediction accuracy on the training set = $\frac{530+552+537+905}{6000}= 0.420$.  

* Note that while the log-likelihood for the mixed logit model is better, in terms of predicting by simply looking at highest probability it is worse than MNL in this example.


### Comparison on test data

```{r}
TestPredict1 <- predict(M1, newdata=Test)
PredictedChoice1 <- apply(TestPredict1,1,which.max)
ActualChoice1 <- subset(safety, Task>12)[,"Choice"]

Tabtestmixed <- table(PredictedChoice1, ActualChoice1)
CorPredTestmixed <- sum(diag(Tabtestmixed))/sum(Tabtestmixed)

Tabtest
CorPredTest

Tabtestmixed
CorPredTestmixed
```

* Prediction accuracy on the test set = $\frac{331+377+316+644}{3500} = 0.4765$.    

* This value is lower than the one obtained for the test set in the MNL model.

* The mixed logit model does a better job of predicting customers who are not interested in choosing any of the offered options compared to MNL.

### Comparing MNL and Mixed model on the Test set (with log-likelihood) -- OPTIONAL

We can also compare out of sample (test) log-likelihood. This is often considered a good measure for the quality of fit of the data.

```{r}
ActualChT <- subset(safety, Task>12)
ActChT <- cbind(ActualChT$Ch1,ActualChT$Ch2,ActualChT$Ch3,ActualChT$Ch4)

# ActChT
# TestPredict

MNLtestLL <- sum(ActChT*log(TestPredict))
MixedtestLL <- sum(ActChT*log(TestPredict1))

MNLtestLL
MixedtestLL
```

Clearly the log-likelihood for the MNL model given by `r round(MNLtestLL,digits=2)` is more than the log-likelihood for the Mixed logit model given by `r round(MixedtestLL, digits=2)`. Hence in this regard as well, the MNL model may be preferred.

