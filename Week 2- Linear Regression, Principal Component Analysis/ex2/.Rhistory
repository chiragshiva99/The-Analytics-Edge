auto -> read.csv(Auto.csv)
auto <- read.csv(Auto.csv)
auto <- read.csv(Auto.csv)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
auto <- read.csv("Auto.csv")
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
str(auto)
#q1
auto <- read.csv("Auto.csv")
str(auto) #horsepower is a STRING. Change it to numeric
#a
#ans) horsepower variable needs to be changed because it is shown as a  chr format.
# convert it into num format
auto$horsepower <- as.numeric(as.character(auto$horsepower))
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
#q1
auto <- read.csv("Auto.csv")
str(auto) #horsepower is a STRING. Change it to numeric
#a
#ans) horsepower variable needs to be changed because it is shown as a  chr format.
# convert it into num format
auto$horsepower <- as.numeric(as.character(auto$horsepower))
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
?predict.lm
predict(model1, newdata = data.frame(horsepower=98), interval = c('confidence'), level= .99)
?cor
cor(auto$mpg, auto$horsepower, use = "everything")^2
cor(auto$mpg, auto$horsepower, use = "pairwise.complete.obs")^2
cor(auto$mpg, auto$horsepower, use = "complete.obs")^2
cor(auto$mpg, auto$horsepower, use = "pairwise.complete.obs")^2
?llm
?lm\
?lm
?ggplot
#e
library(ggplot2)
?ggplot
ggplot(data = auto, mapping = aes(horsepower, mpg)) + geompoint(na.rm=T) + geom_smooth()
ggplot(data = auto, mapping = aes(horsepower, mpg)) + geom_point(na.rm=T) + geom_smooth()
?geom_smooth
ggplot(auto,aes(horsepower,mpg))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T,se=F)
ggplot(auto,aes(horsepower,mpg))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T)
ggplot(auto,aes(horsepower,mpg))+geom_point()+geom_smooth(method="lm")
ggplot(auto,aes(horsepower,mpg))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T,se=F)
#f
library(ggfortify)
autoplot(model1)
autoplot(model1,label.size = 3)
autoplot(model1)
#2
library(psych)
?pairs.panels
pairs.panerls(auto)
pairs.panels(auto)
?panels
?pairs.panels
pairs.panels(auto)
#pairs.panels(auto)
pairs.panels(auto,ellipses = F, lm =T, breaks=10, hist.col="blue")
#pairs.panels(auto)
pairs.panels(auto,ellipses = F, lm =T, breaks=10, hist.col="blue")
?corr
?cor
#d
cor(auto$horsepower, auto$mpg, use = "pairwise.complete.obs")^2
View(auto)
#d
cor(auto$mpg, auto$horsepower, use = "pairwise.complete.obs")^2
#d
cor(auto$horsepower, auto$mpg, use = "pairwise.complete.obs")^2
?subset
#b
#create a new model to exclude last column
auto1 <- subset(auto, select = -c(name))
str(auto1)
cor(auto1)
?cor
cor(auto1, use="complete.obs")
#c
model2<- lm(mpg~, data=auto1)
summary(model2)
#c
model2<- lm(mpg~, data=auto1)
#c
model2<- lm(mpg~., data=auto1)
summary(model2)
set.seed(1)
x1 <- runif(100)
x2 <- 0.5*x1 + rnorm(100)/10
y <- 2 + 2*x1 + 0.3*x2 + rnorm(100)
y
?cor
cor(x1,x2)
?ggplot
?cbind
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
ggplot(cbind(x1,x2),aes(x1,x2))+geom_point()
ggplot()
ggplot(cbind(x1,x2),aes(x1,x2))+geom_point()
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
?cbind
ggplot(cbind(x1,x2),aes(x1,x2))+geom_point()
model3 <- lm(y~x1+x2)
summary(model3)
model13 <- lm(medv~lstat, data=boston)
summary(model13)
model13 <- lm(medv~lstat, data=boston)
boston <- read.csv("Boston.csv")
colnames(boston)
model13 <- lm(medv~lstat, data=boston)
summary(model13)
ggplot(boston,aes(lstat,medv))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T,se=F)
modelall<- lm(medv~., data=boston)
summary(modelall)
?attr
?attr
attr(modelall$coefficients, "names")[modelall$coefficients <= 0.05]
#d
modelall<- lm(medv~lstat + (lstat)^2, data=boston)
?poly
modelpoly<- lm(medv~lstat + (lstat)^2, data=boston)
summary(modelpoly)
modelpoly<- lm(medv~poly(lstat,2), data=boston)
summary(modelpoly)
modelpoly<- lm(medv~poly(lstat,2, raw=TRUE), data=boston)
summary(modelpoly)
modelpoly<- lm(medv~poly(lstat,2), data=boston)
summary(modelpoly)
modelpoly<- lm(medv~poly(lstat,2, raw=TRUE), data=boston)
summary(modelpoly)
#5
wine<-read.csv("winedata.csv")
str(wine)
?mean
subset
?subset
#a
age91 <- 1991 - wine$vintage
age92 <- 1992 - wine$vintage
mean(subset(wine$price91, wine$price91 >= 15 ))
mean(subset(wine$age91, wine$age91 >= 15 ))
mean(subset(wine$price91, wine$age91 >= 15 ))
#a
#create new colums
wine$age91 <- 1991 - wine$vintage
wine$age92 <- 1992 - wine$vintage
mean(subset(wine$price91, wine$age91 >= 15 ))
mean(wine$temp)
mean(wine$tempdiff)
#c
train <- subset(wine, wine$vintage <= 1981)
model1 <- lm(log(price)~age91, data= train)
summary(model1)
summary(model1)
#c
train <- subset(wine, vintage <= 1981)
model1 <- lm(log(price)~age91, data= train)
summary(model1)
#5
wine<-read.csv("winedata.csv")
str(wine)
#a
#create new colums
wine$age91 <- 1991 - wine$vintage
wine$age92 <- 1992 - wine$vintage
mean(subset(wine$price91, wine$age91 >= 15 ))
mean(subset(wine$price91,
wine$hrain < mean(wine$hrain)
&
wine$tempdiff < mean(wine$tempdiff)))
#c
train <- subset(wine, vintage <= 1981)
model1 <- lm(log(price)~age91, data= train)
summary(model1)
train<-subset(wine,vintage<=1981)
model1<-lm(log(price91)~age91,data=train)
summary(model1)
#c
train <- subset(wine, vintage <= 1981)
model1 <- lm(log(price91)~age91, data= train)
summary(model1)
#c
train <- subset(wine, wine$vintage <= 1981)
model1 <- lm(log(price91)~age91, data= train)
summary(model1)
?confint
#d
confint(model1)
#d
confint(model1, level = .99)
?predict
test<-subset(wine,vintage>=1982)
predtest<-predict(model1,newdata=test)
predtest
#e
#testing the model
test<-subset(wine,vintage>=1982)
predtest<-predict(model1,newdata=test)
predtest
log(test$price91)
sse<-sum((log(test$price91)-predtest)^2)
sse
sst<-sum((log(test$price91)-mean(log(train$price91)))^2)
sst
sst-sse
# 6
#a
iris
dim(iris)
summary(iris)
str(iris)
?subset
head(iris[,-5])
head(iris[,5])
head(iris[,-4])
head(iris[,5])
head(iris[5])
head(iris[5,])
#b
iris_data<-iris[,-5] #[ROW, COLUMN]
iris_sp<-iris[,5]
#c
library(psych)
pairs.panels(iris_data, ellipses = F, lm =T, breaks=10, hist.col="blue")
?prcomp
#d
prcomp(data=iris_data, scale= F)
#d
prcomp(iris_data, scale= F)
#d
pr_out <- prcomp(iris_data, scale= F)
summary(pr_out)
cpve<-cumsum(pve)
cpve
pr_out$sdev
pve<-pr_out$sdev^2/sum(pr_out$sdev^2)
cpve<-cumsum(pve)
pve
cpve
?cumsum
?cumsum
plot(cpve,xlab="Principal components",type="l",ylim=c(0.7,1))
library(factoextra)
install.packages("factoextra")
#d (ii)
library(factoextra)
?fviz_ca_biplot
fviz_pca_biplot(pr_out, label = "var", habillage=iris_sp)
fviz_pca_biplot(pr_out, label = "var", habillage=iris_sp,addEllipses=TRUE, ellipse.level=0.95)
