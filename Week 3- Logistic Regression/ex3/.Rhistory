var2 = var_comb[2],
aic = summary(model)$aic))
}
#iterate through all the original variables (single variables)
for (model in model_list_1) {
aic_table_1 <- rbind(aic_table_1,
data.frame(var1 = names(model$coefficients)[2],
var2 = NA,  # NULL does not work
aic = model$aic))
}
aic_table_1
#find model with minimun AIC
aic_table_1[which.min(aic_table_1[,3]),]
subset(aic_table_1, min(aic_table_1$aic))
?subset
subset(aic_table_1, aic_table_1$aic)
subset(aic_table_1, aic>100)
subset(aic_table_1, aic= min(aic))
subset(aic_table_1, aic= min(aic))
?min
subset(aic_table_1, aic= min(aic_table_1$aic))
subset(aic_table_1, aic= min(aic_table_1$aic))
#find model with minimun AIC
aic_table_1[which.min(aic_table_1[,3]),]
#use this to help you clear your environment :)
setdiff(ls(), ls(pattern = "SETUP"))
#use this to help you clear your environment :)
setdiff(ls(), ls(pattern = "SETUP"))
rm(list = setdiff(ls(), ls(pattern = "SETUP")))
#q2
Parole <- read.csv("Parole.csv")
#a
nrow(Parole)
subset(Parole, Parole$Violator=1)
subset(Parole, Parole$Violator==1)
nrow(subset(Parole, Parole$Violator==1))
?sapply
#c
sapply(Parole, class)
sapply(Parole[sapply(Parole, is.factor)], nlevels) #get the number of levels of each column
Parole
sapply(Parole[sapply(Parole, is.factor)], nlevels) #get the number of levels of each column
#c
sapply(Parole, class)
#d
set.seed(144)
library(caTools)
install.packages("caTools")
#d
set.seed(144)
library(caTools)
s1 <- sample.split(Parole$Violator, SplitRatio = 0.7)
tr1 <- subset(Parole, s1 == TRUE)
te1 <- subset(Parole, s1 == FALSE)
?identical
set.seed(144)
library(caTools)
s1 <- sample.split(Parole$Violator, SplitRatio = 0.7)
tr1 <- subset(Parole, s1 == TRUE)
te1 <- subset(Parole, s1 == FALSE)
set.seed(144)
library(caTools)
s2 <- sample.split(Parole$Violator, SplitRatio = 0.7)
tr2 <- subset(Parole, s2 == TRUE)
te2 <- subset(Parole, s2 == FALSE)
identical(s1, s2, FALSE, FALSE, FALSE, FALSE)
identical(tr1, tr2, FALSE, FALSE, FALSE, FALSE)
identical(te1, te2, FALSE, FALSE, FALSE, FALSE)
set.seed(144)
library(caTools)
s1 <- sample.split(Parole$Violator, SplitRatio = 0.7)
tr1 <- subset(Parole, s1 == TRUE)
te1 <- subset(Parole, s1 == FALSE)
#e
set.seed(144)
library(caTools)  # not required by this point
split <- sample.split(Parole$Violator, SplitRatio = 0.7)
train <- subset(Parole, split == TRUE)
test <- subset(Parole, split == FALSE)
model_2 <- glm(Violator ~ ., data = train, family = binomial)
summary(model_2)
#extracting the significant variables with p-value below 0.05
model_2$residuals
#extracting the significant variables with p-value below 0.05
model_2$coefficients
#extracting the significant variables with p-value below 0.05
model_2$coefficients
#extracting the significant variables with p-value below 0.05
summary(model_2$coefficients)
#extracting the significant variables with p-value below 0.05
summary(model_2)$coefficients
#extracting the significant variables with p-value below 0.05
summary(model_2)$coefficients
p_val_2_e <- coed_table[:-1]
#extracting the significant variables with p-value below 0.05
coed_table <- summary(model_2)$coefficients
p_val_2_e <- coed_table[:-1]
#extracting the significant variables with p-value below 0.05
coed_table <- summary(model_2)$coefficients
p_val_2_e <- coed_table[,-1]
p_val_2_e
p_val_2_e <- coed_table[,4]
p_val_2_e
#extracting the significant variables with p-value below 0.05
coed_table <- summary(model_2)$coefficients
p_val_2_e <- coed_table[,4]
sigvars <- names(p_val_2_e[p_val_2_e<=0.05])
#extracting the significant variables with p-value below 0.05
coef_table_2 <- summary(model_2)$coefficients #save the coefficients for later use
p_val_2_e <- coef_table_2[,4]
sig_vars_2 <- names(p_val_2_e[p_val_2_e <= 0.05])
sig_vars_2
summary(model_2)
#f
# Get the corresponding coefficient of the 'MultipleOffenses' variable (amount of increase in log odds if one comitted multiple offenses)
# Use row name to extract row (check spelling!); column 1 corresponds to coefficient column
coef_multiple <- coef_table_2["MultipleOffenses", 1]
exp(coef_multiple) # odds
summary(model_2)
#f
# Get the corresponding coefficient of the 'MultipleOffenses' variable (amount of increase in log odds if one comitted multiple offenses)
# Use row name to extract row (check spelling!); column 1 corresponds to coefficient column
coef_multiple <- coef_table_2["MultipleOffenses", 1]
exp(coef_multiple) # odds
#g
# Here we prep the coefficients we need
coef_2 <- coef_table_2 #includes many coefficients we don't need
# We want to remove the coefficients for StateLouisiana, StateOther, StateVirginia, CrimeDrugs, CrimeOther
coef_2 <- coef_2[!(startsWith(rownames(coef_2), "State")  |
startsWith(rownames(coef_2), "Crime")) |
rownames(coef_2) == "CrimeLarceny",]
# Based on information given, define x_2
x_2 <- c(1,  # intercept
1,  # male
1,  # white
50, # age
3,  # time served
12, # max sentence
0,  # multiple offenses
1)  # larceny
logodds_2 <- coef_2[,1] %*% x_2  # matrix mult
#logodds_2
#exp(logodds_2)
prob = exp(logodds_2)/ (1+exp(logodds_2))
prob
?predict
#h
pred_2_h <- predict(model_2, newdata = test, type = "response")
max(pred_2_h)
#i
pred_table_2 <- table((pred_2_h > 0.5), test$Violator)
pred_table_2
# sensitivity (true positive rate)
pred_table_2[2,2]/sum(pred_table_2[,2])
# specificity (true negative rate)
pred_table_2[1,1]/sum(pred_table_2[,1])
# accuracy (accuracy)
sum(diag(pred_table_2)/sum(pred_table_2))
#m
suppressMessages(library(ROCR))  # suppressMessages not critical - this is used as loading this library prints dependencies loaded
install.packages("ROCR")
#m
suppressMessages(library(ROCR))  # suppressMessages not critical - this is used as loading this library prints dependencies loaded
# Make a prediction and find the model performance using predicted values
predrocr_2 <- prediction(pred_2_h, test$Violator)
auc_2 <- performance(predrocr_2, measure = "auc")@y.values[[1]]
auc_2 # AUC value (area under curve) - the closer to 1, the better
setdiff(ls(), ls(pattern = "SETUP"))
rm(list = setdiff(ls(), ls(pattern = "SETUP")))
germancredit <- read.csv("germancredit")
germancredit <- read.csv("germancredit")
germancredit <- read.csv("germancredit.csv")
head(germancredit)
set.seed(2019)
library(caTools)
spl <- samplesplit(germancredit$resp, 0.75)
training <- subset(germancredit, spl == TRUE)
test <- subset(germancredit, spl == FALSE)
spl <- samplesplit(germancredit$resp, 0.75)
set.seed(2019)
library(caTools)
spl <- samplesplit(germancredit$resp, 0.75)
set.seed(2019)
library(caTools)
spl <- sample.split(germancredit$resp, 0.75)
training <- subset(germancredit, spl == TRUE)
test <- subset(germancredit, spl == FALSE)
#b
model_3 <- glm(resp ~ 1, data = training, family = binomial)
summary(model_3)
summary(model_3)$Coefficients
summary(model_3)$coefficients
#b
model_3 <- glm(resp ~ 1, data = training, family = binomial)
x <- summary(model_3)
x$coefficients
x$coefficients[1]
#calculating probability
exp(x) / (1+exp(x))
x <- summary(model_3)
x <- x$coefficients[1]
#calculating probability
exp(x) / (1+exp(x))
x
#b
model_3 <- glm(resp ~ 1, data = training, family = binomial)
x <- summary(model_3)
x <- x$coefficients[1]
x
#calculating probability
exp(x) / (1+exp(x))
#b
mmodel_3_b <- glm(resp ~ 1, data = training, family = binomial)
x <- model_3_b$coefficients[1]
x # intercept
#calculating probability
exp(x) / (1+exp(x))
#c
# Variable 'resp' gives the credit rating of the respondents
n_good <- table(training$resp)["1"]
n_bad <- table(training$resp)["0"]
n_good/(n_good+n_bad) # same as probability of resp=1 in simple logistic regression model in (b)
#d
mmodel_3_d <- glm(resp ~. , data = training, family = binomial)
#d
model_3_d <- glm(resp ~. , data = training, family = binomial)
#d
model_3_d <- glm(resp ~. , data = training, family = binomial)
summary(model_3_d)
x <- summary(model_3_d)
x$coefficients
#d
model_3_d <- glm(resp ~. , data = training, family = binomial)
p_val <- summary(model_3_d)$coefficients[,4]
p_val
#d
model_3_d <- glm(resp ~. , data = training, family = binomial)
p_val <- summary(model_3_d)$coefficients[,4]
p_val
names(p_val[p_val < 0.1])
#d
model_3_d <- glm(resp ~ ., data = training, family = binomial)
#summary(model_3_d)
p_val_3 <- summary(model_3_d)$coefficients[,4] #p values
sig_vars_3 <- names(p_val_3[p_val_3 <= 0.10]) #10% level
sig_vars_3
#e
?deviance
#d
model_3_d <- glm(resp ~ ., data = training, family = binomial)
#summary(model_3_d)
p_val_3 <- summary(model_3_d)$coefficients[,4] #p values
sig_vars_3 <- names(p_val_3[p_val_3 <= 0.10]) #10% level
sig_vars_3
#e
summary(model_3_d)
-model_3_d$deviance/2
#f
pred_table <- table((predictor > 0.5), test$resp)
#f
pred <- predict(model_3_d, newdata = test, type = "response")
max(pred)
#f
pred <- predict(model_3_d, newdata = test, type = "response")
max(pred)
pred_table <- table((pred > 0.5), test$resp)
pred_table
#f
pred <- predict(model_3_d, newdata = test, type = "response")
max(pred)
pred_table <- table((pred > 0.5), test$resp)
pred_table
# sensitivity (true positive rate)
#The Sensitivity (True Positive Rate) is 12/(11+12)=0.521
pred_table[2,2]/sum(pred_table[,2])
# specificity (true negative rate)
#The Specificity (True Negative Rate) is 167/(167+12)=0.932
pred_table[1,1]/sum(pred_table[,1])
# accuracy (accuracy)
#The Accuracy is (167+12)/(167+11+12+12)=0.886
sum(diag(pred_table)/sum(pred_table))
sig_vars_3
#f
# using the suffix 3_d because (d) will be the reference to this model
pred_3_d <- predict(model_3_d, newdata = test, type = "response")
# at threshold 0.5
table(pred_3_d >= 0.5, test$resp)
#g
# sensitivity (true positive rate)
pred_table[2,2]/sum(pred_table[,2])
# specificity (true negative rate)
pred_table[1,1]/sum(pred_table[,1])
# accuracy (accuracy)
sum(diag(pred_table)/sum(pred_table))
"chkacct"    "hist"       "newcar"     "amt"        "sav"        "emp"
#h
model_3_h <- glm(resp ~ chkacct, data = training, family = binomial)
summary(model_3_h)
#h
model_3_h <- glm(resp ~ chkacct+hist+newcar+amt+sav+emp+instrate+malesingle+guar+other+for. , data = training, family = binomial)
summary(model_3_h)
#h
model_3_h <- glm(resp ~ chkacct+hist+newcar+amt+sav+emp+instrate+malesingle+guar+other+for. , data = training, family = binomial)
x <- summary(model_3_h)
x$aic
#h
model_3_h <- glm(resp ~ -1 +chkacct+hist+newcar+amt+sav+emp+instrate+malesingle+guar+other+for. , data = training, family = binomial)
x <- summary(model_3_h)
x$aic
#h
# using predictor vairables significant at 10% level
model_3_h <- glm(as.formula(
paste0("resp ~ ",
paste0(sig_vars_3, collapse = " + "),
"- 1")  # intercept not significant at 3(d)
) , data = training, family = binomial)
model_3_h$aic # aic - the lower the better
#j
# using the suffix 3_d because (d) will be the reference to this model
pred_3_h <- predict(model_3_h, newdata = test, type = "response")
# at threshold 0.5
table(pred_3_h >= 0.5, test$resp)
# at threshold 0.5
table(pred_3_d >= 0.5, test$resp)
# at threshold 0.5
table(pred_3_h >= 0.5, test$resp)
#k
#l
#m
auc_d <- performance(pred_3_d, measure = "auc")@y.values[[1]]
auc_2 # AUC value (area under curve) - the closer to 1, the better
#k
#l
#m
auc_d <- performance(pred_3_d, measure = "auc")@y.values[[1]]
?performance
#k
#l
#m
suppressMessages(library(ROCR))  # suppressMessages not critical - this is used as loading this library prints dependencies loaded
# Make a prediction and find the model performance using predicted values
predrocr_1 <- prediction(pred_2_d, test$Violator)
#k
#l
#m
suppressMessages(library(ROCR))  # suppressMessages not critical - this is used as loading this library prints dependencies loaded
# Make a prediction and find the model performance using predicted values
predrocr_1 <- prediction(pred_3_d, test$Violator)
predrocr_2 <- prediction(pred_3_h, test$Violator)
# Make a prediction and find the model performance using predicted values
predrocr_1 <- prediction(pred_3_d, test$resp)
predrocr_2 <- prediction(pred_3_h, test$resp)
#k
#l
#m
suppressMessages(library(ROCR))  # suppressMessages not critical - this is used as loading this library prints dependencies loaded
# Make a prediction and find the model performance using predicted values
predrocr_1 <- prediction(pred_3_d, test$resp)
predrocr_2 <- prediction(pred_3_h, test$resp)
auc_d <- performance(predrocr_1, measure = "auc")@y.values[[1]]
auc_d # AUC value (area under curve) - the closer to 1, the better
auc_h <- performance(predrocr_2, measure = "auc")@y.values[[1]]
auc_h # AUC value (area under curve) - the closer to 1, the better
#n
model_3_d <- glm(resp ~ ., data = training, family = binomial)
#f
# using the suffix 3_d because (d) will be the reference to this model
pred_3_d <- predict(model_3_d, newdata = test, type = "response")
# at threshold 0.5
table(pred_3_d >= 0.5, test$resp)
pred_3_d <- predict(model_3_d, newdata = test, type = "response")
table(pred_3_d >= 0.5, test$resp)
table(pred_3_d >= 0.5, test$resp)[2,1]
profit <- (table(pred_3_d >= 0.5, test$resp)[2,1])*(-300) + table(pred_3_d >= 0.5, test$resp)[2,2]*(100)
profit
rocr_3_d <- prediction(pred_3_d, test$resp)
auc_3_d <- performance(rocr_3_d, measure = "auc")@y.values
auc_3_d[[1]] #auc for model d
rocr_3_h <- prediction(pred_3_h, test$resp)
auc_3_h <- performance(rocr_3_h, measure = "auc")@y.values
auc_3_h[[1]] #auc for model h
#n
model_3_d <- glm(resp ~ ., data = training, family = binomial)
pred_3_d <- predict(model_3_d, newdata = test, type = "response")
table(pred_3_d >= 0.5, test$resp)
profit <- (table(pred_3_d >= 0.5, test$resp)[2,1])*(-300) + table(pred_3_d >= 0.5, test$resp)[2,2]*(100)
profit
profit <- sum(pred_table_3_d * matrix(c(0,-300,0,100), nrow = 2, ncol = 2))
profit
profit <- sum(pred_table_3_d * matrix(c(0,-300,0,100), nrow = 2, ncol = 2))
profit
?sum
?sort
#o
# Sort predicted probability from high to low
sort_pred_3_d <- sort(pred_3_d, decreasing = TRUE)
# Get the duration of the last individual
lowest_prob <- sort_pred_3_d[length(sort_pred_3_d)]
last_man <- names(lowest_prob) # index of row with lowest prob
germancredit[last_man, ]$dur # duration of credit
lowest_prob
sort_pred_3_d
sort_pred_3_d
#o
# Sort predicted probability from high to low
sort_pred_3_d <- sort(pred_3_d, decreasing = TRUE)
# Get the duration of the last individual
lowest_prob <- sort_pred_3_d[length(sort_pred_3_d)]
lowest_prob
last_man <- names(lowest_prob) # index of row with lowest prob
germancredit[last_man, ]$dur # duration of credit
lowest_prob
#p
# first we get the sorted predictions
# we need index.return to give the indices with respect to pred_3_d
# which derives from the test set
# there might be other ways of doing this, but this is probably the most convenient way
sort_pred_3_p <- sort(pred_3_d, decreasing = TRUE, index.return = TRUE)
profit_pred_3 <- ifelse(test$resp[sort_pred_3_p$ix], 100, -300)
cumulative_profit_3 <- cumsum(profit_pred_3)
# then we simply return what was asked for in the question
which.max(cumulative_profit_3)
max(cumulative_profit_3) #the max amount of profits
#q
# Find the predicted probability of the individual with index 153 on sorted test set
# NOTE: individiual with 153 on sorted test set may not be index 153 on unsorted/raw test set
sort_pred_3_p$x[which.max(cumulative_profit_3)]
#END________
setdiff(ls(), ls(pattern = "SETUP"))
rm(list = setdiff(ls(), ls(pattern = "SETUP")))
#q4
pres <- read.csv("presidential.csv")
?table
#a
sum(pres$WIN)
table(pres$WIN)
?table
#b
table(pres$DEM)
maxtable(pres$DEM)
max(table(pres$DEM))
name(max(table(pres$DEM)))
subset(pres, pres$WIN["1"])
subset(pres, pres$WIN == 1)
max(table(pres$DEM, subset(pres, pres$WIN == 1)))
max(table(subset(pres$DEM, pres$WIN == 1)))
max(table(subset(pres$DEM, pres$WIN == -1)))
#b
table(pres$DEM)
max(table(subset(pres$DEM, pres$WIN == 1)))
table(subset(pres$DEM, pres$WIN == 1))
sort(table(pres$DEM))
sort(table(pres$REP))
names(which.max(table(pres$DEM)))
max(table(pres$DEM))
names(which.max(table(pres$REP)))
max(table(pres$REP))
#b
table(pres$DEM)
sort(table(pres$DEM))
sort(table(pres$REP))
names(which.max(table(pres$DEM)))
max(table(pres$DEM))
names(which.max(table(pres$REP)))
max(table(pres$REP))
table(pres$DEM)
sort(table(pres$DEM))
sort(table(pres$REP))
#c
t.test(pres$GOOD[pres$INC==1],pres$GOOD[pres$INC==-1])
#c
x <- t.test(pres$GOOD[pres$INC==1],pres$GOOD[pres$INC==-1])
x$p.value
?t.test
#d
pres$WININC <- as.integer(pres$INC==pres$WIN)
#e
table(pres$WININC)
#f
model1 <- glm(WININC~GROWTH,data=pres,family=binomial)
summary(model1)
llm1<-(model1$aic - 2*model1$rank)/2
llm1 #log likelihood
?logLik
logLik(model1) #log likelihood
summary(model1)$coefficients[2,4] #p-value for GROWTH variable
#g
presmod<-pres
presmod$WIN <- as.integer(pres$WIN==1)
presmod$GROWTH <- pres$GROWTH*pres$INC
logLik(model1) #log likelihood
summary(model1)$coefficients[2,4] #p-value for GROWTH variable
#g
presmod<-pres
presmod$WIN <- as.integer(pres$WIN==1)
presmod$GROWTH <- pres$GROWTH*pres$INC
#i
presmod$GOOD <- pres$GOOD*pres$INC
presmod
model2 <- glm(WIN~INC+RUN+GROWTH+DUR+GOOD,data=presmod,family=binomial)
summary(model2)
x <- summary(model2)
x$aic
#k
model2 <- glm(WIN~RUN+GROWTH+DUR-1,data=presmod,family=binomial)
model2$aic
#k
# Drop intercept, INC and GOOD
model3 <- glm(WIN~RUN+GROWTH+DUR-1, data=presmod, family=binomial)
summary(model3)
newdat <- data.frame(RUN=-1, GROWTH=5, DUR=0)
predict(model3, newdat, type="response")
